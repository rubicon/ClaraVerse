#!/bin/sh
set -e

# =============================================================================
# ClaraVerse Unified Docker Entrypoint
# =============================================================================
# Handles first-run setup, auto-secret generation, and configuration.
# Secrets are persisted to /app/data/ so they survive container restarts.
# =============================================================================

echo "================================================"
echo "  ClaraVerse - Starting up..."
echo "================================================"

# Ensure data directories exist
mkdir -p /app/data /app/uploads /app/logs

# ---------------------------------------------------------------------------
# Auto-generate JWT_SECRET if not provided
# ---------------------------------------------------------------------------
if [ -z "$JWT_SECRET" ]; then
    KEY_FILE="/app/data/.jwt_secret"
    if [ ! -f "$KEY_FILE" ]; then
        echo "[init] Generating JWT secret key..."
        head -c 32 /dev/urandom | base64 | tr -d '\n' > "$KEY_FILE"
    else
        echo "[init] Loading existing JWT secret from data volume"
    fi
    export JWT_SECRET=$(cat "$KEY_FILE")
fi

# ---------------------------------------------------------------------------
# Auto-generate ENCRYPTION_MASTER_KEY if not provided
# ---------------------------------------------------------------------------
if [ -z "$ENCRYPTION_MASTER_KEY" ]; then
    KEY_FILE="/app/data/.encryption_key"
    if [ ! -f "$KEY_FILE" ]; then
        echo "[init] Generating encryption master key..."
        head -c 32 /dev/urandom | od -A n -t x1 | tr -d ' \n' > "$KEY_FILE"
    else
        echo "[init] Loading existing encryption key from data volume"
    fi
    export ENCRYPTION_MASTER_KEY=$(cat "$KEY_FILE")
fi

# ---------------------------------------------------------------------------
# Create providers.json from example if not present
# ---------------------------------------------------------------------------
PROVIDERS_PATH="${PROVIDERS_FILE:-/app/data/providers.json}"
if [ ! -f "$PROVIDERS_PATH" ]; then
    if [ -f "/app/providers.example.json" ]; then
        echo "[init] Creating default providers.json (configure via UI or edit the file)"
        cp /app/providers.example.json "$PROVIDERS_PATH"
    fi
fi

# ---------------------------------------------------------------------------
# Generate runtime config.js for frontend (allows runtime env overrides)
# ---------------------------------------------------------------------------
if [ "$SERVE_FRONTEND" = "true" ] && [ -d "/app/public" ]; then
    # Determine API/WS URLs - empty means same-origin (all-in-one mode)
    API_URL="${CLARA_API_BASE_URL:-}"
    WS_URL="${CLARA_WS_URL:-}"

    cat > /app/public/config.js << JSEOF
// Runtime configuration - generated by docker-entrypoint
// Overrides build-time VITE_* variables when running in Docker
window.__CLARA_CONFIG__ = {
  API_BASE_URL: "${API_URL}",
  WS_URL: "${WS_URL}",
  APP_NAME: "${CLARA_APP_NAME:-ClaraVerse}",
};
JSEOF
    echo "[init] Frontend runtime config generated"
fi

# ---------------------------------------------------------------------------
# Copy SearXNG settings to volume if not present (for compose deployments)
# ---------------------------------------------------------------------------
if [ -f "/app/config/searxng-settings.yml" ] && [ -d "/app/data" ]; then
    if [ ! -f "/app/data/searxng-settings.yml" ]; then
        cp /app/config/searxng-settings.yml /app/data/searxng-settings.yml
        echo "[init] SearXNG default settings copied to data volume"
    fi
fi

# ---------------------------------------------------------------------------
# Detect local AI providers (Ollama / LM Studio) on host machine
# ---------------------------------------------------------------------------
OLLAMA_STATUS="not detected"
LMSTUDIO_STATUS="not detected"

OLLAMA_URL="${OLLAMA_BASE_URL:-http://host.docker.internal:11434}"
if wget -q --spider --timeout=2 "$OLLAMA_URL" 2>/dev/null; then
    OLLAMA_STATUS="detected at $OLLAMA_URL"
    echo "[init] Found Ollama at $OLLAMA_URL — models will be auto-imported"
fi

LMSTUDIO_URL="${LMSTUDIO_BASE_URL:-http://host.docker.internal:1234}"
if wget -q --spider --timeout=2 "$LMSTUDIO_URL/v1/models" 2>/dev/null; then
    LMSTUDIO_STATUS="detected at $LMSTUDIO_URL"
    echo "[init] Found LM Studio at $LMSTUDIO_URL — models will be auto-imported"
fi

# ---------------------------------------------------------------------------
# Display startup info
# ---------------------------------------------------------------------------
echo ""
echo "  Port:        ${PORT:-3000}"
echo "  Environment: ${ENVIRONMENT:-production}"
echo "  Frontend:    ${SERVE_FRONTEND:-false}"
echo "  Database:    ${DATABASE_URL:+configured}"
echo "  MongoDB:     ${MONGODB_URI:+configured}"
echo "  Redis:       ${REDIS_URL:+configured}"
echo "  SearXNG:     ${SEARXNG_URL:+configured}"
echo "  Ollama:      $OLLAMA_STATUS"
echo "  LM Studio:   $LMSTUDIO_STATUS"
echo ""
echo "================================================"
echo ""

# Execute the main application
exec "$@"
